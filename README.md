# NLPEntityExtract
一句话介绍：音乐家人物生平故事抽取，运用到NLP的实体抽取，Python正则表达式


## 使用前准备
1. Python 3
2. pip安装pyhanlp库
3. 为pyhanlp库添加自定义词典，用文件夹里的“全国地名大全.txt”替换安装路径：
`..\Anaconda3\Lib\site-packages\pyhanlp\static\data\dictionary\custom`  下的 **全国地名大全.txt** 文件

#### 悲伤心路历程及经验教训

        1> 我尝试添加自定义词典，但是失败了……就搞了个笨办法直接加到原有的字典里
        
        2> 新的txt是添加了外国国家名和城市名，如果后期有合适的字典或没有识别出的地名，可以添加到安装路径下的该文件
        
        3> 添加新的地名时要小心格式问题，不能直接打开txt复制用\n隔开的词！！我采取的做法是，在Spyder里打开这个txt文件，然后复制用\n隔开的词，保存
        
        4> 更新词典后，要重启一下Spyder或pycharm，因为要重新import不然就还是用的旧词典


4. 入口函数：**myMain.py** 中的 **doExtract()**

    传入参数为文件名（不含后缀，默认为txt格式）
    
    无返回值，生成的提取文件名为“原文件名_out.txt”或“原文件名_out.csv”


## 数据说明
1. 输入数据：txt格式

    随意粘贴一段即可，无格式要求，但是，编码一定要用notepad++转成utf-8
    
    但是，我目前按照百度百科的人物生平格式来做的抽取，可能对于大段的讲故事型的生平抽取事件效果不是特别好。

2. 输出数据

    抽取的一条数据有如下字段：
* **time**：时间结点（如，1999年3月7日，1999年3月，1999年）或时间段（如，1999年-2000年）
* **person**：出现的人名
* **location**：地名或机构名
* **work**：以《》提取的音乐作品名
* **keyword**：高频词（默认3个，可以再改）
* **abstract**：摘要句（文章中原句，最关键的1句话）
* **filter**：将摘要句分词、去除停词等，只保留句子主干，即摘要句的精简版

#### PS

    time的格式目前只匹配了年月日和xxxx-xx-xx的格式，如果有需要可以再加
    
    person和location的提取，使用的是pyhanlp训练的结果，提取外国人名有时会出错，但不知道怎么改了……

3. 两种输出文件，txt和csv

    txt读取啰嗦，但编码没问题；csv读取简单，但编码有毛病

**txt输出**
* 一条数据，按“time，person，location，work，keyword，abstract，filter”的顺序，每一项字段输出后换行，为空的字段为空行
* 每条数据分为7行，各条数据之间无间隔

**csv输出**
* 列名就是上述的字段名
* 中文编码还存在蜜汁bug/…… 在Spyder里看这个csv文件是ok的，但是用txt或Excel打开中文字符是乱码……实在是不知道怎么搞了
